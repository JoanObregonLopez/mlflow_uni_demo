{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and Data Loading\n",
    "\n",
    "In this section, we load the MNIST dataset and perform normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalizing data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Expanding dimensions to add a grayscale channel\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "\n",
    "We build a convolutional neural network model to classify MNIST images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the deep learning model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Setting up the optimizer\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "We define the training parameters and train the model, using MLflow to log metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 20s 42ms/step - loss: 0.2072 - accuracy: 0.9394 - val_loss: 0.0546 - val_accuracy: 0.9830\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0553 - accuracy: 0.9829 - val_loss: 0.0455 - val_accuracy: 0.9856\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 0.0424 - val_accuracy: 0.9867\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0289 - accuracy: 0.9914 - val_loss: 0.0309 - val_accuracy: 0.9898\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 19s 41ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0297 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JOANOB~1\\AppData\\Local\\Temp\\tmp7f7k0m34\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JOANOB~1\\AppData\\Local\\Temp\\tmp7f7k0m34\\model\\data\\model\\assets\n",
      "Setuptools is replacing distutils.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x1ef8020cc70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Starting an MLflow experiment\n",
    "mlflow.start_run()\n",
    "\n",
    "# Logging parameters to MLflow\n",
    "mlflow.log_param(\"epochs\", epochs)\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "mlflow.log_param(\"optimizer\", \"adam\")\n",
    "mlflow.log_param(\"learning_rate\", 0.001)\n",
    "\n",
    "# Trainning the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "# Saving the model to MLflow\n",
    "mlflow.keras.log_model(model, artifact_path=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "We evaluate the model on the test set and log the final metrics to MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9899\n",
      "Test loss: 0.02968001924455166, Test accuracy: 0.9898999929428101\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_acc}')\n",
    "\n",
    "# Logging final metrics to MLflow\n",
    "mlflow.log_metric(\"test_loss\", test_loss)\n",
    "mlflow.log_metric(\"test_accuracy\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Explanation with SHAP\n",
    "\n",
    "We generate explanations for the model's predictions using SHAP and save them in MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    }
   ],
   "source": [
    "# Creating a directory for SHAP images if it doesn't exist\n",
    "shap_images_dir = \"shap_images\"\n",
    "os.makedirs(shap_images_dir, exist_ok=True)\n",
    "\n",
    "# Using SHAP to explain the model\n",
    "background = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "test_images = x_test[:5]\n",
    "\n",
    "# Creating the SHAP explainer and get SHAP values\n",
    "explainer = shap.GradientExplainer(model, background)\n",
    "shap_values = explainer.shap_values(test_images)\n",
    "\n",
    "# Getting the model predictions\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Saving SHAP explanations in MLflow\n",
    "for i in range(len(test_images)):\n",
    "    shap_image = os.path.join(shap_images_dir, f\"shap_explanation_{i}.png\")\n",
    "    shap_value = shap_values[predicted_classes[i]][i]\n",
    "    \n",
    "    # Visualizing and save the SHAP explanation\n",
    "    shap.image_plot([shap_value], -test_images[i], show=False)\n",
    "    plt.savefig(shap_image, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Logging the image to MLflow\n",
    "    mlflow.log_artifact(shap_image, artifact_path=\"shap_images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End the MLflow Experiment\n",
    "\n",
    "We end the experiment run in MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ending the MLflow run\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
